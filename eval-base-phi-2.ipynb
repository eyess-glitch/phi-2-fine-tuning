{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T19:53:57.011145Z","iopub.status.busy":"2024-02-10T19:53:57.010875Z","iopub.status.idle":"2024-02-10T19:55:26.428474Z","shell.execute_reply":"2024-02-10T19:55:26.427454Z","shell.execute_reply.started":"2024-02-10T19:53:57.011119Z"},"trusted":true},"outputs":[],"source":["!pip install accelerate bitsandbytes datasets peft transformers einops"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T19:55:40.250840Z","iopub.status.busy":"2024-02-10T19:55:40.250471Z","iopub.status.idle":"2024-02-10T19:55:47.096798Z","shell.execute_reply":"2024-02-10T19:55:47.095123Z","shell.execute_reply.started":"2024-02-10T19:55:40.250806Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","# Load the Phi 2 model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\n","    \"microsoft/phi-2\",\n","    trust_remote_code=True,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"/kaggle/input/train-qlora-alpaca-2048-r64\",\n","    device_map=\"auto\",\n","    torch_dtype=\"auto\",\n","    trust_remote_code=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-10T19:55:26.438544Z","iopub.status.idle":"2024-02-10T19:55:26.438895Z","shell.execute_reply":"2024-02-10T19:55:26.438712Z","shell.execute_reply.started":"2024-02-10T19:55:26.438698Z"},"trusted":true},"outputs":[],"source":["from transformers import GenerationConfig, TextStreamer, pipeline\n","\n","generation_config = GenerationConfig.from_pretrained(\"microsoft/phi-2\")\n","generation_config.max_new_tokens = 512\n","generation_config.temperature = 0.8\n","generation_config.do_sample = True\n","\n","streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n","\n","llm = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    return_full_text=False,\n","    generation_config=generation_config,\n","    num_return_sequences=1,\n","    eos_token_id=tokenizer.eos_token_id,\n","    pad_token_id=tokenizer.eos_token_id,\n","    streamer=streamer,\n",")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T13:33:17.417531Z","iopub.status.busy":"2024-02-11T13:33:17.417149Z","iopub.status.idle":"2024-02-11T13:33:38.119759Z","shell.execute_reply":"2024-02-11T13:33:38.118650Z","shell.execute_reply.started":"2024-02-11T13:33:17.417499Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'human-eval'...\n","remote: Enumerating objects: 29, done.\u001b[K\n","remote: Counting objects: 100% (20/20), done.\u001b[K\n","remote: Compressing objects: 100% (16/16), done.\u001b[K\n","remote: Total 29 (delta 8), reused 4 (delta 4), pack-reused 9\u001b[K\n","Receiving objects: 100% (29/29), 54.20 KiB | 623.00 KiB/s, done.\n","Resolving deltas: 100% (9/9), done.\n","Obtaining file:///kaggle/working/human-eval\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from human-eval==1.0) (4.66.1)\n","Collecting fire (from human-eval==1.0)\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from human-eval==1.0) (1.24.3)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->human-eval==1.0) (1.16.0)\n","Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->human-eval==1.0) (2.3.0)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=64a8144ba196de972218903bc05285895b8f2b54eee89615ee843df2038baf97\n","  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n","Successfully built fire\n","Installing collected packages: fire, human-eval\n","  Running setup.py develop for human-eval\n","Successfully installed fire-0.5.0 human-eval-1.0\n","/kaggle/working/human-eval\n"]}],"source":["! git clone https://github.com/openai/human-eval\n","! pip install -e human-eval\n","%cd human-eval"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-10T19:55:26.442724Z","iopub.status.idle":"2024-02-10T19:55:26.443171Z","shell.execute_reply":"2024-02-10T19:55:26.442962Z","shell.execute_reply.started":"2024-02-10T19:55:26.442941Z"},"trusted":true},"outputs":[],"source":["from human_eval.data import write_jsonl, read_problems\n","\n","problems = read_problems()\n","\n","num_samples_per_task = 3\n","samples = [\n","    dict(task_id=task_id, completion=llm(problems[task_id][\"prompt\"]))\n","    for task_id in problems\n","    for _ in range(num_samples_per_task)\n","]\n","write_jsonl(\"train_samples.jsonl\", samples)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T13:33:38.154963Z","iopub.status.busy":"2024-02-11T13:33:38.154725Z","iopub.status.idle":"2024-02-11T13:33:38.176261Z","shell.execute_reply":"2024-02-11T13:33:38.175530Z","shell.execute_reply.started":"2024-02-11T13:33:38.154942Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Nuovo file JSONL salvato in: /kaggle/working/human-eval/train_samples_formatted.jsonl\n"]}],"source":["import json\n","\n","def create_jsonl_object(task_id, completion_text):\n","    return {\"task_id\": task_id, \"completion\": completion_text}\n","\n","def process_jsonl_file(input_file_path, output_file_path):\n","    # Leggi il file JSONL\n","    with open(input_file_path, 'r') as file:\n","        lines = file.readlines()\n","\n","    # Parsa ogni riga e crea la lista di oggetti\n","    jsonl_objects = []\n","    for line in lines:\n","        json_line = json.loads(line)\n","        task_id = json_line['task_id']\n","        completion_text = json_line['completion'][0]['generated_text']  # Assumendo che ci sia solo un elemento in 'completion'\n","        \n","        jsonl_objects.append(create_jsonl_object(task_id, completion_text))\n","\n","    with open(output_file_path, 'w') as output_file:\n","        for obj in jsonl_objects:\n","            output_file.write(json.dumps(obj) + '\\n')\n","\n","input_file_path = '/kaggle/input/train-samples/train_samples.jsonl'\n","output_file_path = '/kaggle/working/human-eval/train_samples_formatted.jsonl'\n","    \n","process_jsonl_file(input_file_path, output_file_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T13:33:44.371709Z","iopub.status.busy":"2024-02-11T13:33:44.370983Z","iopub.status.idle":"2024-02-11T13:33:44.448204Z","shell.execute_reply":"2024-02-11T13:33:44.447421Z","shell.execute_reply.started":"2024-02-11T13:33:44.371678Z"},"trusted":true},"outputs":[],"source":["import json\n","\n","def process_jsonl(input_file, output_file):\n","    with open(input_file, 'r') as f_in, open(output_file, 'w') as f_out:\n","        for line in f_in:\n","            data = json.loads(line)\n","            completion = data['completion']\n","            if '__name__ == \"__main__\":' in completion:\n","                index = completion.find('if __name__ == \"__main__\":')\n","                modified_completion = completion[:index]\n","                data['completion'] = modified_completion\n","            json.dump(data, f_out)\n","            f_out.write('\\n')\n","\n","input_file = '/kaggle/working/human-eval/train_samples_formatted.jsonl'\n","output_file = '/kaggle/working/human-eval/train_samples_cleaned.jsonl'\n","\n","process_jsonl(input_file, output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["! cat /kaggle/input/human-eval-code-repo/human-eval-master/human_eval/execution.py > /kaggle/working/human-eval/human_eval/execution.py\n","! cat /kaggle/input/eval-file/evaluation.py > /kaggle/working/human-eval/human_eval/evaluation.py \n","! chmod +x /kaggle/working/human-eval/human_eval/evaluate_functional_correctness.py \n","! python human_eval/evaluate_functional_correctness.py /kaggle/working/human-eval/train_samples_cleaned.jsonl"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4260705,"sourceId":7338730,"sourceType":"datasetVersion"},{"datasetId":4382114,"sourceId":7522556,"sourceType":"datasetVersion"},{"datasetId":4382166,"sourceId":7522662,"sourceType":"datasetVersion"},{"datasetId":4413952,"sourceId":7582523,"sourceType":"datasetVersion"},{"datasetId":4425500,"sourceId":7601910,"sourceType":"datasetVersion"},{"datasetId":4425578,"sourceId":7602025,"sourceType":"datasetVersion"},{"datasetId":4428196,"sourceId":7605848,"sourceType":"datasetVersion"},{"datasetId":4475149,"sourceId":7672291,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
